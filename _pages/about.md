---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>
<div style="text-align: justify;">
Yuan Gao is currently pursuing Ph.D. degree in School of Science at Tsinghua University.    He received B.Sc. degree in School of Navigation from the Wuhan University of Technology, in 2024   <br><br>   His research interests include AI for Science and Computer Vision.    He has published over 10 papers at the top international conferences and journals    (<a href='https://scholar.google.com.hk/citations?user=4JpRnU4AAAAJ&hl=zh-CN'><img src="https://img.shields.io/endpoint?url={{ url | url\_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>)  such as ICML, ECCV, IEEE TITS, IEEE TIM, KBS, OCMA. He has also served as a reviewer of multiple conferences and journals,    including IEEE TITS, Neural Networks.   <br><br><strong>I am actively seeking like-minded collaborators.</strong>    If you are interested in my work, please feel free to contact me via email:    yuangao24@mails.tsinghua.edu.cn.
</div>

# ğŸ”¥ News

- **2025.05**: &nbsp;ğŸ‰ One paper has been accepted by **<a href="https://icml.cc/">ICML 2025</a>** (First Author).
- **2024.09**: &nbsp;ğŸ‰ One paper have been accepted by **<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6979/">IEEE TITS</a>**.
- **2024.07**: &nbsp;ğŸ‰ One paper has been accepted by **<a href="https://eccv.ecva.net/">ECCV 2024</a>** (Co-first Author).
- **2024.06**: &nbsp;ğŸ‰ One paper have been accepted by **<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=19/">IEEE TIM</a>** (First Author).
- **2024.04**: &nbsp;ğŸ‰ One paper has been accepted by **<a href="https://www.sciencedirect.com/journal/knowledge-based-systems/">KBS</a>**.
- **2023.08**: &nbsp;ğŸ‰ One paper have been accepted by **<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6979/">IEEE TITS</a>**.
- **2023.07**: &nbsp;ğŸ‰ One paper have been accepted by **<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=19/">IEEE TIM</a>** (First Author).
- **2023.01**: &nbsp;ğŸ‰ One paper have been accepted by **<a href="https://www.sciencedirect.com/journal/ocean-and-coastal-management/">OCMA</a>** (Co-first Author).


# ğŸ“ Publications

<p style="text-align: left; font-weight: bold; font-size: 1.2em; margin-bottom: -0.5em;">Representative Works (â€  means equal contribution)</p>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV 2024</div><img src='papers/ECCV2024_OneRestore/abstract.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[OneRestore: A Universal Restoration Framework for Composite Degradation](https://arxiv.org/abs/2407.04621)

<strong>Yu Guo</strong><sup>â€ </sup>, Yuan Gao<sup>â€ </sup>, Yuxu Lu, Huilin Zhu, Ryan Wen Liu, Shengfeng He

[**Project**](https://gy65896.github.io/projects/ECCV2024_OneRestore/index.html)

<a href="https://arxiv.org/abs/2407.04621" target="_blank">Paper</a> |  <a href="https://www.youtube.com/embed/AFr5tZdPlZ4">Video</a> |  <a href="https://gy65896.github.io/papers/ECCV2024_OneRestore/OneRestore_poster.png">Poster</a> | <a href="https://onedrive.live.com/?id=CBB69E4E3408EBCD%2138238&resid=CBB69E4E3408EBCD%2138238&ithint=folder&authkey=%21AMxuLGqPrvXXQ4c&cid=cbb69e4e3408ebcd" target="_blank">Dataset</a> |
<a href="https://github.com/gy65896/OneRestore" target="_blank">Code</a> <img src="https://img.shields.io/github/stars/gy65896/OneRestore?label=%F0%9F%8C%9F%20Star&color=blue"> <img src="https://img.shields.io/github/forks/gy65896/OneRestore?label=%F0%9F%94%A7%20Fork&color=green">

</div>
</div>

<p style="text-align: center; font-weight: bold; font-size: 1.2em; margin-bottom: 0.5em;">2025</p>

- *Yuan Gao**<sup>â€ </sup>, Hao Wu<sup>â€ </sup>, Ruiqi Shu<sup>â€ </sup>, Huanshuo Dong, Fan Xu, Rui Chen, Yibo Yan, Qingsong Wen, Xuming Hu, Kun Wang, Jiahao Wu, Qing Li, Hui Xiong, Xiaomeng Huang, [OneForecast: A Universal Framework for Global and Regional Weather Forecasting](), **ICML 2025**

<p style="text-align: center; font-weight: bold; font-size: 1.2em; margin-bottom: 0.5em;">2024</p>

- Yu Guo<sup>â€ </sup>, **Yuan Gao**<sup>â€ </sup>, Yuxu Lu, Huilin Zhu, Ryan Wen Liu, Shengfeng He, [OneRestore: A Universal Restoration Framework for Composite Degradation](https://arxiv.org/abs/2407.04621), **ECCV 2024** 
- Ryan Wen Liu, Yuxu Lu, **Yuan Gao**, Yu Guo, Wenqi Ren, Fenghua Zhu, Fei-Yue Wang, [Real-Time Multi-Scene Visibility Enhancement for Promoting Navigational Safety of Vessels Under Complex Weather Conditions](https://ieeexplore.ieee.org/abstract/document/10682473/), **IEEE TITS**
- Wenyu Xu, Dong Yang, **Yuan Gao**, Yuxu Lu, Jingming Zhang, Yu Guo, [MvKSR: Multi-view Knowledge-guided Scene Recovery for Hazy and Rainy Degradation](https://ieeexplore.ieee.org/abstract/document/10598186/), **IEEE TIM**
- Yuxu Lu, Dong Yang, **Yuan Gao**, Ryan Wen Liu, Jun Liu, Yu Guo, [AoSRNet: All-in-One Scene Recovery Networks via Multi-knowledge Integration](https://www.sciencedirect.com/science/article/pii/S0950705124004209), **KBS**
- Jingxiang Qu, Ryan Wen Liu, **Yuan Gao**, Yu Guo, Fenghua Zhu, Fei-Yue Wang, [Double Domain Guided Real-time Low-light Image Enhancement for Ultra-high-definition Transportation Surveillance](https://ieeexplore.ieee.org/abstract/document/10423894/), **IEEE TITS**

<p style="text-align: center; font-weight: bold; font-size: 1.2em; margin-bottom: 0.5em;">2023</p>

- Yu Guo, **Yuan Gao**, Wen Liu, Yuxu Lu, Jingxiang Qu, Shengfeng He, Wenqi Ren, [SCANet: Self-paced Semi-curricular Attention Network for Non-homogeneous Image Dehazing](https://openaccess.thecvf.com/content/CVPR2023W/NTIRE/html/Guo_SCANet_Self-Paced_Semi-Curricular_Attention_Network_for_Non-Homogeneous_Image_Dehazing_CVPRW_2023_paper.html), **CVPRW 2023**

# ğŸ– Honors and Awards

* <b>Ph.D. National Scholarship</b> <b>(Top 1%)</b>, 2023, Rank: 1.

# ğŸ“– Educations

* **ğŸ“ Ph.D. in School of Science, 2024 - Now**

<span style="color:darkgray; padding-left: 4em;">Tsinghua University, Beijing, China</span>

* **ğŸ“ B.Sc. in School of Navigation, 2020 - 2024**

<span style="color:darkgray; padding-left: 4em;">Wuhan University of Technology, Wuhan, China

# ğŸ’» Internships

* **ğŸ“ Research Assistant, 2024.10 - Now**

<span style="color:darkgray; padding-left: 4em;">City University of Hong Kong, Hong Kong, China

* **ğŸ“ Remote Intern, 2024.07 - 2024.10**

<span style="color:darkgray; padding-left: 4em;">City University of Hong Kong, Hong Kong, China

